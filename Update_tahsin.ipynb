new_code = ["def add(a, b): return a + b"]
new_sequence = tokenizer_code.texts_to_sequences(new_code)
new_padded = pad_sequences(new_sequence, maxlen=padded_code.shape[1])
predicted_sequence = model.predict(new_padded)
predicted_summary = [tokenizer_summary.index_word[idx] for idx in tf.argmax(predicted_sequence, axis=-1).numpy()[0] if idx != 0]
predicted_summary = " ".join(predicted_summary)
print(f"Predicted Summary: {predicted_summary}")
